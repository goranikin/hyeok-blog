[
  {
    "title": "텍스트 애널리틱스 팀 프로젝트 - LitSearch dataset Augmentation",
    "description": "LitSearch dataset의 증강 과정에 대해 서술합니다.",
    "slug": "text-analytics",
    "publishDate": "2025-06-26",
    "thumbnailUrl": "/study/project/text-analytics/thm.png",
    "content": "const{Fragment:n,jsx:e,jsxs:r}=arguments[0];function _createMdxContent(i){const t={a:\"a\",br:\"br\",code:\"code\",h3:\"h3\",hr:\"hr\",img:\"img\",li:\"li\",ol:\"ol\",p:\"p\",strong:\"strong\",ul:\"ul\",...i.components};return r(n,{children:[e(t.p,{children:e(t.a,{href:\"https://github.com/goranikin/snu_retrieval\",children:\"GitHub Repository\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h3,{children:\"Background\"}),\"\\n\",e(t.p,{children:\"팀원이 주제를 제안 - 학술 논문 Retrieval 성능을 높여보기\"}),\"\\n\",e(t.p,{children:\"서칭해준 논문 및 Dataset을 바탕으로 시작.\"}),\"\\n\",e(t.p,{children:r(t.strong,{children:[\"Dataset - \",e(t.a,{href:\"https://arxiv.org/abs/2407.18940\",children:\"LitSearch\"})]})}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"S2ORC dataset에서 추출한 64000개의 paper corpus (id, title, abstract, full text) 기반\"}),\"\\n\",e(t.li,{children:\"특정 논문을 검색하는 query를 해당 논문 저자에게 작성해달라고 요청\"}),\"\\n\",e(t.li,{children:\"이후 LLM을 활용해 추가 생성 후, 저자들의 수작업 검수\"}),\"\\n\",e(t.li,{children:\"Query data는 논문을 검색하는 query text와 정답 논문 id label (query, paper id)\"}),\"\\n\",e(t.li,{children:\"이 외 query에 대한 추가적인 정보 데이터들 존재\"}),\"\\n\"]}),\"\\n\",e(t.p,{children:e(t.strong,{children:\"Model\"})}),\"\\n\",r(t.ul,{children:[\"\\n\",r(t.li,{children:[e(t.a,{href:\"https://arxiv.org/abs/2004.07180\",children:\"SPECTER2\"}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"과학 논문으로 훈련된 SciBERT checkpoint\"}),\"\\n\",e(t.li,{children:\"논문 triplet을 이용해 임베딩 공간을 학습\"}),\"\\n\",e(t.li,{children:\"Adapter를 통해 Downstream task 수행 가능\"}),\"\\n\"]}),\"\\n\"]}),\"\\n\",r(t.li,{children:[e(t.a,{href:\"https://arxiv.org/abs/2004.04906\",children:\"DPR\"}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"BERT-base model\"}),\"\\n\",e(t.li,{children:\"Dual Encoder 구조 - Question encoder | Passage encoder\"}),\"\\n\"]}),\"\\n\"]}),\"\\n\",r(t.li,{children:[e(t.a,{href:\"https://arxiv.org/abs/2107.05720\",children:\"SPLADE\"}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"BERT-base model\"}),\"\\n\",e(t.li,{children:\"Sparse Search를 위해 MLM Head를 이용\"}),\"\\n\",e(t.li,{children:e(t.a,{href:\"https://europe.naverlabs.com/blog/splade-a-sparse-bi-encoder-bert-based-model-achieves-effective-and-efficient-first-stage-ranking/\",children:\"Retrieval의 흐름과 SPLADE에 대한 설명 블로그\"})}),\"\\n\"]}),\"\\n\"]}),\"\\n\"]}),\"\\n\",e(t.h3,{children:\"Structure\"}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/1.png\",alt:\"\"})}),\"\\n\",e(t.p,{children:\"이미 성숙한 Retrieval 분야에서 LLM을 활용한 개선 방안 모색.\"}),\"\\n\",r(t.ol,{children:[\"\\n\",e(t.li,{children:\"Query Rewriting\"}),\"\\n\",e(t.li,{children:\"HyDE (query를 기반으로 LLM이 생성한 할루시네이션 문서를 임베딩해 유사도로 검색)\"}),\"\\n\",e(t.li,{children:\"Data Augmentation\"}),\"\\n\"]}),\"\\n\",e(t.p,{children:\"이 중 3번, Data Augmentation(데이터 증강)을 맡아서 진행.\"}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h3,{children:\"Why and How\"}),\"\\n\",e(t.p,{children:e(t.strong,{children:\"Pain point\"})}),\"\\n\",r(t.p,{children:[\"LitSearch Dataset은 많은 인력의 노동을 요구하며, 이로 인해 567개밖에 존재하지 않음\",e(t.br,{}),\"\\n\",\"→ 실제로 Finetuning 시 과적합 문제가 발생함\"]}),\"\\n\",e(t.p,{children:\"LitSearch 논문에서 진행한 LLM 활용 query 생성 방식을 사용\"}),\"\\n\",r(t.ol,{children:[\"\\n\",e(t.li,{children:\"특정 논문을 인용하는 문장인 Inline Citation Sentence를 활용\"}),\"\\n\",e(t.li,{children:\"Inline Citation Sentence를 Input으로 하여 인용되는 논문을 검색하는 쿼리 생성\"}),\"\\n\"]}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"파이프라인 구상\"}),\"\\n\",e(t.img,{src:\"/study/project/text-analytics/3.png\",alt:\"\"})]}),\"\\n\",r(t.ol,{children:[\"\\n\",e(t.li,{children:\"데이터 증강에 필요한 context data 추출 및 전처리\"}),\"\\n\",e(t.li,{children:\"Qwen3:14b 모델을 사용해 query 데이터 증강\"}),\"\\n\",e(t.li,{children:\"증강된 데이터의 퀄리티 검증\"}),\"\\n\"]}),\"\\n\",e(t.p,{children:e(t.strong,{children:\"증강 데이터 검증 방식\"})}),\"\\n\",r(t.ol,{children:[\"\\n\",e(t.li,{children:\"BM25 recall 점수 유사도\"}),\"\\n\"]}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"LitSearch dataset에서 query에 대한 여러 모델의 Retrieval 성능 존재\"}),\"\\n\",e(t.li,{children:\"이 중 키워드 기반 Sparse Search의 근본인 BM25 점수가 증강 데이터에서 유사하게 나타나면 1차 통과\"}),\"\\n\"]}),\"\\n\",r(t.ol,{start:\"2\",children:[\"\\n\",e(t.li,{children:\"Finetuning 후 모델의 성능 증가\"}),\"\\n\"]}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"증강 데이터로 finetuning 진행\"}),\"\\n\",e(t.li,{children:\"finetuned model이 기존 LitSearch Dataset에 대해 더 높은 성능을 보이면 최종 검증 완료\"}),\"\\n\"]}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"데이터 전처리 과정\"}),\" (팀 프로젝트 발표 자료)\"]}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/4.png\",alt:\"\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/5.png\",alt:\"\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/6.png\",alt:\"\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/7.png\",alt:\"\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/8.png\",alt:\"\"})}),\"\\n\",e(t.hr,{}),\"\\n\",r(t.p,{children:[\"데이터 전처리와 관련된 코드는 \",e(t.a,{href:\"https://github.com/goranikin/snu_retrieval/tree/main/src/data_augmentation\",children:\"링크 (src/data_augmentation)\"}),\" 중, \",e(t.code,{children:\"/generate_query/extracting_ctss.py\"}),\"에 작성.\",e(t.br,{}),\"\\n\",\"+ 해당 파일을 Vessl ai 내에서 컨테이너로 띄워 동작하는 \",e(t.code,{children:\"extracting_ctss.yaml\"}),\".\"]}),\"\\n\",e(t.p,{children:\"위와 동일하게 이후 과정을 로컬이나 Jupyter 환경이 아닌, py와 yml 파일을 활용하여 LLMOps 플랫폼 내에서 실행.\"}),\"\\n\",e(t.p,{children:\"ㅡ\"}),\"\\n\",e(t.p,{children:e(t.strong,{children:\"Query 생성 및 Triplet 완성\"})}),\"\\n\",e(t.p,{children:\"가장 최근에 출시된 좋은 성능을 가진 qwen3:14b 모델 사용.\"}),\"\\n\",r(t.p,{children:[e(t.a,{href:\"https://github.com/goranikin/snu_retrieval/tree/main/src/data_augmentation/generate_query\",children:\"링크 (src/data_augmentation)\"}),\" 모듈 및 상위 디렉토리의 \",e(t.code,{children:\"data_augmentation.yaml\"}),\"로 실행.\",e(t.br,{}),\"\\n\",\"쿼리 증강 프롬프트 시행착오 총 7회는 위 링크의 \",e(t.code,{children:\"Prompt.md\"}),\"에 기록.\"]}),\"\\n\",r(t.p,{children:[\"Data Augmentation 결과 총 1000개의 query 생성.\",e(t.br,{}),\"\\n\",\"최종 생성된 쿼리의 BM25 Recall 20 점수는 0.429 → 기존 LitSearch 점수는 0.399로 1차 검증 통과.\"]}),\"\\n\",e(t.p,{children:\"SPECTER2 논문에 언급된 Easy Negative : Hard Negative = 3 : 2 비율로, 쿼리 하나당 positive 1, negative 5 쌍이 존재 → 1000개의 query로 5000개의 triplet 생성.\"}),\"\\n\",r(t.p,{children:[\"triplet 생성 과정은 \",e(t.a,{href:\"https://github.com/goranikin/snu_retrieval/blob/main/src/data_augmentation/make_triplet/make_triplet.py\",children:\"/data_augmentation/generate_query/make_triplet/make_triplet.py\"}),\"에서 REPL 환경으로 진행.\"]}),\"\\n\",e(t.p,{children:e(t.strong,{children:\"Finetuning 결과\"})}),\"\\n\",e(t.p,{children:e(t.img,{src:\"/study/project/text-analytics/9.png\",alt:\"\"})}),\"\\n\",e(t.p,{children:\"Adapter 방식을 통한 PEFT가 Retrieval embedding 모델에 효과적이라고 판단.\"}),\"\\n\",e(t.p,{children:\"SPLADE-v3 모델의 성능 저하 - 모델에 대한 근본적 이해 부족\"}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"Sparse Search가 목표민 모델에 대해, vector db상의 유사도를 triplet으로 조정하는 finetuning 방식은 당연히 기존 모델의 지식 구조를 붕괴시킬 수밖에 없음. 이에 대해서 실험 전에는 큰 생각 없이 막연하게 '해볼만하지 않을까' 싶었고, 막상 결과를 보니 당연했던 결과라 느껴짐.\"}),\"\\n\",r(t.li,{children:[\"추가로 \",e(t.a,{href:\"https://github.com/naver/splade\",children:\"SPLADE 레포지토리\"}),\"에 잘 만들어진 코드들을 보고 내가 짜놓은 구조에 끼워 맞추는 과정이 있었음. 여기서 코드 단위의 통합을 좇다가 loss나 regularizer 등 실험적 요소들을 제대로 챙기지 못한 점도 성능 하락의 원인 중 하나.\"]}),\"\\n\"]}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h3,{children:\"Self-Reflection\"}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"데이터 전처리 및 증강 과정\"}),e(t.br,{}),\"\\n\",\"증강을 위한 context data 추출에서 겪은 많은 실패가 있었다. inline citation sentence와 cited paper를 짝지어 얻는 과정부터 시간 소모가 컸는데, 이 부분도 그렇고 전 과정에서 데이터셋을 천천히 살펴보며 설계했다면 훨씬 시간을 아꼈을 듯하다. 이건 프로젝트 전체적으로도 많이 느꼈다. 코딩하기 전에 설계부터 하자.\"]}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"프롬프트 엔지니어링\"}),e(t.br,{}),\"\\n\",\"증강의 첫 시도가 직접 보기에도 매우 실망스러운 수준이라 당황했다. 여러 조건을 바꿔가며 진행할 때마다 점점 결과물이 좋아지는 걸 보며, LLM을 다룰 때 프롬프트 엔지니어링이 얼마나 중요한지도 체감했다. 단순히 trial-error 반복이 아니라, 이전 결과를 보고 나름의 가설을 세워 다시금 프롬프트를 적용해 원하는 결과를 얻어내려면 LLM 자체에 대한 이해가 필수라 생각.\"]}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"코드 구현\"}),e(t.br,{}),\"\\n\",\"이 부분은 프로젝트에는 그닥 필요 없지만 혼자서 코드로 만들며 고생한 부분이다. 편하게 실험하도록 된 API를 쓰기보다 직접 클래스로 구현해보려 했고, 무엇보다 Jupyter Notebook이 아닌 Vessl AI에서 container를 띄우는 yml 파일을 작성해 실행시키려 했다. 이 과정에서 수많은 Failed를 마주하고 디버깅할 때 코드의 근본적인 문제가 있음을 깨달았다. 기능들이 올바르게 분리되어 있지 않고 하나의 클래스에 몰려있는 점, 로그부터 assertion, error handling 등등. 프론트와 근본적으로 다른 코드 구조를 가져가야 함을 run 돌릴 때 확실히 깨달았다. 아래는 finetuning만을 위해 70번 넘게 Run을 돌린 흔적. 일단 실패하고, 로그 보고 조금씩 고치다보니 저렇게 됐다.\\n\",e(t.img,{src:\"/study/project/text-analytics/10.png\",alt:\"\"})]}),\"\\n\",e(t.h3,{children:\"Future Direction\"}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"모델에 대한 이해\"}),e(t.br,{}),\"\\n\",\"모델에 대한 논문을, 특히 모델 설계와 실험 조건 및 과정 부분을 자세히 읽고 활용했을 듯하다. 이를 간과하고 무작정 코딩하다 시간을 더 소모하기도 했고, 애초에 잘못된 설계를 하기도 했다. 특히 SPLADE를 제대로 활용하지 못한 점이 너무 아쉬웠다. 다음 번에는 천천히 모델의 특징을 알아보고 적절한 방법론을 채택해보려 노력해볼 것이다.\"]}),\"\\n\",r(t.p,{children:[e(t.strong,{children:\"지저분한 코드\"}),e(t.br,{}),\"\\n\",\"SPLADE 모델 코드를 보면서 반성을 많이 했다. 유지보수와 디버깅이 용이하도록 추상화, 분리하는 과정이 필요하고, 그 전에 기본적으로 파이썬이란 언어를 좀 더 잘 이해할 필요도 있다.\"]})]})}return{default:function(n={}){const{wrapper:r}=n.components||{};return r?e(r,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/study/project/text-analytics"
  },
  {
    "title": "텍스트 애널리틱스 수업 팀 프로젝트 - Finetuning Pipeline",
    "description": "증강된 데이터로 Finetuning Pipeline을 작성한 코드를 설명합니다.",
    "slug": "text-analytics2",
    "publishDate": "2025-06-27",
    "thumbnailUrl": "/study/project/text-analytics/1.png",
    "content": "const{Fragment:n,jsx:e,jsxs:r}=arguments[0];function _createMdxContent(i){const t={a:\"a\",code:\"code\",h2:\"h2\",hr:\"hr\",li:\"li\",ol:\"ol\",p:\"p\",pre:\"pre\",ul:\"ul\",...i.components};return r(n,{children:[e(t.p,{children:e(t.a,{href:\"https://github.com/goranikin/snu_retrieval\",children:\"GitHub Repository\"})}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h2,{children:\"들어가기 전\"}),\"\\n\",r(t.p,{children:[\"프로젝트에 대한 전반적인 설명은 \",e(t.a,{href:\"http://localhost:3000/study/project/text-analytics\",children:\"이전 글\"}),\"을 참고해주세요.\"]}),\"\\n\",e(t.p,{children:\"객체 지향이나 여러 디자인 원칙 등을 제대로 학습하지 않고 프로젝트를 진행했습니다. 전반적인 구조부터 코드의 설계가 단단히 잘못되었음을 인지하고 있었으나, 이를 리뷰해주는 사람이 없어 급한대로 LLM을 최대한 활용해 모듈을 분리했습니다.\"}),\"\\n\",e(t.p,{children:\"이후 SPLADE 모델의 코드를 천천히 보며 추상화와 의존성 주입이 잘 된 코드를 확인할 수 있었고, 종강 이후 더 좋은 설계가 무엇일지 리팩토링 하는 시간을 가졌습니다. 이때 '파이썬 클린코드 (Clean Code in Python)'와 인프런 파이썬 강의를 수강하며 Python이란 언어 자체를 이해하고자 했습니다.\"}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h2,{children:\"Finetuning 구조\"}),\"\\n\",r(t.p,{children:[e(t.a,{href:\"https://github.com/goranikin/snu_retrieval/tree/main/src/finetune_pipeline\",children:\"src/finetune_pipeline\"}),\"에는 base 디렉토리에 공통 모듈을 작성하고, SPECTER2, DPR, SPLADE 세 모델의 디렉토리를 분리하여 작성했다. 각각의 모델 디렉토리마다 model.py, trainer.py를 정의한 뒤, finetune.py에서 두 클래스를 활용해 파인튜닝을 진행한다.\"]}),\"\\n\",e(t.p,{children:\"파일 구조\"}),\"\\n\",e(t.pre,{children:e(t.code,{className:\"language-Bash\",children:\"finetune_pipeline/\\n├── README.md\\n├── base/\\n│   ├── data.py\\n│   ├── loss.py\\n│   └── retrieval.py\\n├── data/\\n│   └── triplet_data.json\\n├── dpr/\\n│   ├── README.md\\n│   ├── finetune_inbatch.py\\n│   ├── finetune_triplet.py\\n│   ├── model.py\\n│   ├── trainer_inbatch.py\\n│   └── trainer_triplet.py\\n├── specter2/\\n│   ├── README.md\\n│   ├── evaluate.py\\n│   ├── finetune.py\\n│   ├── finetune_specter2_with_the_augmented_data.ipynb\\n│   ├── model.py\\n│   ├── trainer.py\\n├── splade/\\n│   ├── README.md\\n│   ├── finetune.py\\n│   ├── train.py\\n│   ├── trainer.py\\n│   ├── conf/\\n\"})}),\"\\n\",r(t.p,{children:[\"SPECTER2, DPR, SPLADE 세 모델은 Query와 Document를 따로 인코딩한다는 공통점이 있다. 이러한 구조를 추상화한 클래스를 \",e(t.code,{children:\"base/retrieval.py\"}),\"에 작성했다. (Retrieval class는 \",e(t.a,{href:\"https://github.com/princeton-nlp/LitSearch\",children:\"LitSearch Repositry\"}),\"를 많이 참고했다.)\"]}),\"\\n\",e(t.h2,{children:\"현재 코드의 문제점과 해결 방향성\"}),\"\\n\",r(t.ol,{children:[\"\\n\",e(t.li,{children:\"한 클래스에 부과된 많은 기능\"}),\"\\n\"]}),\"\\n\",r(t.ul,{children:[\"\\n\",r(t.li,{children:[\"각 모델을 정의한 \",e(t.code,{children:\"model.py\"}),\"를 보면 클래스 안에 여러 메서드가 존재한다. model loading, encoding, indexing, retrieval 등 매우 다양한 기능들이 혼재되어 있는데, 딱 봐도 하나의 클래스가 너무 많은 역할을 담당하고 있다. 위에서 언급된 기능들을 SPLADE 코드에서는 전부 분리된 클래스로 정의되어 있다. 이를 참고하여 리팩토링한다면 유지보수성은 물론 코드의 가독성이 매우 좋아질 것이다.\"]}),\"\\n\"]}),\"\\n\",r(t.ol,{start:\"2\",children:[\"\\n\",e(t.li,{children:\"무분별하게 선언되는 상수값들\"}),\"\\n\"]}),\"\\n\",r(t.ul,{children:[\"\\n\",e(t.li,{children:\"개발 동아리에서 프론트 기능을 작성할 때는 constants 디렉토리를 따로 두고 관리했지만, 이 코드에서는 우선 돌아가는 기능을 빠르게 작성하다보니 상수 관리를 제대로 하지 못했다. 선언된 값들이 혼재되지 않고 체계적으로 잘 관리할 필요가 있다.\"}),\"\\n\"]}),\"\\n\",e(t.hr,{}),\"\\n\",e(t.h2,{children:\"리팩토링\"}),\"\\n\",r(t.p,{children:[\"리팩토링 과정에서는 \",e(t.a,{href:\"https://github.com/naver/splade\",children:\"SPLADE 레포지토리\"}),\"를 많이 참고했다. 특히 시간에 좇기며 프로젝트를 마무리할 때 SPLADE 코드를 보고, 내 코드와는 차원이 다르게 깔끔하단 걸 깨달았다. 어영부영 프로젝트는 마무리했지만 종강하자마자 곧장 코드 설계와 관련된 책을 읽고, SPLADE 코드를 참고하여 리팩토링하고자 했다. 리팩토링은 우선 가장 많이 시간을 쏟았던 SPECTER2 모델에 대해서만 진행했다.\"]}),\"\\n\",r(t.p,{children:[e(t.a,{href:\"https://github.com/goranikin/snu_retrieval/tree/main/src/refactored_pipeline\",children:\"리팩토링 코드 링크\"}),\"를 보면 구조는 다음과 같다.\"]}),\"\\n\",e(t.pre,{children:e(t.code,{className:\"language-Bash\",children:\"src/refactored_pipeline/\\n├── baseline.py\\n├── finetune.py\\n├── conf/\\n│   └── finetune_specter2.yaml\\n├── datasets/\\n│   ├── data.py\\n│   └── triplet_data.json\\n├── losses/\\n│   └── loss.py\\n├── models/\\n│   └── base.py\\n├── tasks/\\n│   ├── base/\\n│   │   ├── base_trainer.py\\n│   │   ├── early_stopping.py\\n│   │   └── saver.py\\n│   ├── evaluator.py\\n│   └── trainer.py\\n├── utils/\\n│   ├── data_processing_utils.py\\n│   ├── os_utils.py\\n│   └── retrieval_utils.py\\n└── vessl/\\n    ├── baseline.yml\\n    └── finetune.yml\\n\"})}),\"\\n\",e(t.p,{children:\"기존 모델 클래스가 하던 일을 전부 분리했다. indexing, retrieval, finetuning 기능은 tasks에 정의되어 있고, 각각의 클래스들은 model을 파라미터로 받아 분리된 기능을 수행한다. 모델은 models/base.py의 Specter2Base가 추상 클래스인데(abc.ABC 상속) 생성자를 제외하고는 encode, _encode밖에 없다. 오직 인코딩만 담당하는 것이다.\"}),\"\\n\",e(t.p,{children:\"현재는 SPECTER2 모델에 대해서만 리팩토링을 진행하고 있어서 Specter2Base 클래스가 adapter type과 같은 모델에 특수한 값을 지정하고 있다. 만일 다른 모델까지도 묶을 수 있는 상위 추상 클래스를 작성한다면 forward만 정의해야 할 것이다. 그리고 SPLADE는 MLM, DPR은 mean pooling, SPECTER는 CLS를 사용하므로 이에 대한 값을 파라미터로 받아 hidden state에 대해 각기 다른 출력을 반환하도록 작성해볼 수 있겠다. (실은 SPLADE에서 이러한 구조를 사용하고 있다.)\"}),\"\\n\",e(t.p,{children:\"무엇보다 SPLADE 코드에서 가장 재미있었던 건 hydra를 사용한 상수 관리 및 logging과 학습을 도와주는 early_stopping, save 등과 같은 유틸리티들이었다. 이 중 유틸성 클래스들은 우선은 코드에 붙이긴 했지만, 6월 28일 기준으로 당장은 사용하고 있지 않다. 우선 리팩토링 자체가 최우선 목표였으므로... 지금은 log와 파일 관리, 그리고 hydra를 통한 상수값 관리만을 사용하고 있다.\"}),\"\\n\",e(t.p,{children:\"리팩토링하고 나니 훨씬 가독성이 좋아졌다. 디버깅과 싸우며 삽질했던 지난 날이 떠오른다. 이렇게 깔끔한 구조였다면 그렇게 시간을 오래 잡아먹진 않았을텐데. 확실히 잘 쓴 남의 코드를 보고 이해하니 바라보는 게 훨씬 달라진다. 가능하다면 언젠가 AI 관련 오픈 소스를 읽고 기여해보는 경험도 해보고 싶다.\"})]})}return{default:function(n={}){const{wrapper:r}=n.components||{};return r?e(r,{...n,children:e(_createMdxContent,{...n})}):_createMdxContent(n)}};",
    "permalink": "/study/project/text-analytics2"
  }
]